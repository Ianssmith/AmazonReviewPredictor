{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455000, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>helpScore</th>\n",
       "      <th>helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138806</td>\n",
       "      <td>138807</td>\n",
       "      <td>B000E63LME</td>\n",
       "      <td>A1CQGW1AOD0LF2</td>\n",
       "      <td>Alena K. \"Alena\"</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1294185600</td>\n",
       "      <td>Not as pictured.</td>\n",
       "      <td>I was looking forward to try cranberry apple f...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>469680</td>\n",
       "      <td>469681</td>\n",
       "      <td>B004ZIH4KM</td>\n",
       "      <td>A37S7U1OX2MCWI</td>\n",
       "      <td>Becky Cole</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1349740800</td>\n",
       "      <td>seeds</td>\n",
       "      <td>TY for everything.  The seeds arrived quickly,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238202</td>\n",
       "      <td>238203</td>\n",
       "      <td>B003ZXE9QA</td>\n",
       "      <td>A2OM6G73E64EQ9</td>\n",
       "      <td>jeff</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1329264000</td>\n",
       "      <td>I'm addicted!</td>\n",
       "      <td>I've finally found the best cereal in the worl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>485307</td>\n",
       "      <td>485308</td>\n",
       "      <td>B001RVFERK</td>\n",
       "      <td>A25W349EE97NBK</td>\n",
       "      <td>Tangent4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1248307200</td>\n",
       "      <td>I wanted to love these...</td>\n",
       "      <td>I originally bought these chips because I'd he...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>375283</td>\n",
       "      <td>375284</td>\n",
       "      <td>B000OQZNTS</td>\n",
       "      <td>A3CPPW0HUC07YS</td>\n",
       "      <td>Amy Nicolai</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1333238400</td>\n",
       "      <td>Excellent chamomile tea</td>\n",
       "      <td>Really excellent tea, flowers are visible in t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Id   ProductId          UserId       ProfileName  \\\n",
       "0      138806  138807  B000E63LME  A1CQGW1AOD0LF2  Alena K. \"Alena\"   \n",
       "1      469680  469681  B004ZIH4KM  A37S7U1OX2MCWI        Becky Cole   \n",
       "2      238202  238203  B003ZXE9QA  A2OM6G73E64EQ9              jeff   \n",
       "3      485307  485308  B001RVFERK  A25W349EE97NBK          Tangent4   \n",
       "4      375283  375284  B000OQZNTS  A3CPPW0HUC07YS       Amy Nicolai   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       2      2  1294185600   \n",
       "1                     0                       0      5  1349740800   \n",
       "2                     0                       0      5  1329264000   \n",
       "3                     1                       1      4  1248307200   \n",
       "4                     0                       0      5  1333238400   \n",
       "\n",
       "                     Summary  \\\n",
       "0           Not as pictured.   \n",
       "1                      seeds   \n",
       "2              I'm addicted!   \n",
       "3  I wanted to love these...   \n",
       "4    Excellent chamomile tea   \n",
       "\n",
       "                                                Text  helpScore helpful  \n",
       "0  I was looking forward to try cranberry apple f...        0.5   False  \n",
       "1  TY for everything.  The seeds arrived quickly,...        NaN   False  \n",
       "2  I've finally found the best cereal in the worl...        NaN   False  \n",
       "3  I originally bought these chips because I'd he...        1.0   False  \n",
       "4  Really excellent tea, flowers are visible in t...        NaN   False  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Amazon.csv')\n",
    "print(data.shape)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "hv = HashingVectorizer() ##25 represents the distinct words in the \"bag of words\"\n",
    "X = hv.transform(data.Text)\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['hasSC'] = data['Text'].str.contains(';')\n",
    "data['hasbroken'] = data['Text'].str.contains('broken')\n",
    "data['hasdidnt'] = data['Text'].str.contains('didn\\'t')\n",
    "data['hasperfect'] = data['Text'].str.contains('perfect')\n",
    "data['haslove'] = data['Text'].str.contains('love')\n",
    "data['hasEP'] = data['Text'].str.contains('!')\n",
    "data['hasdash'] = data['Text'].str.contains('-')\n",
    "\n",
    "data['reviewLen'] = data['Text'].str.len()\n",
    "data['duplicateIds'] = data.UserId.duplicated()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0      Id   ProductId          UserId  \\\n",
      "10000      387073  387074  B001874C30  A2Q7GPAKVFRSUP   \n",
      "10001      100953  100954  B000Z4SWII  A1JTRDU8P560MS   \n",
      "10002      384241  384242  B004S04X56  A36WGHR8TO5DKT   \n",
      "10003      378078  378079  B002GJ9JY6   AV0OB90U6I1QQ   \n",
      "10004      203603  203604  B004OQ257C  A277GP2U2TXH51   \n",
      "10005      108800  108801  B001FYUVG8  A19Y3Z5SFLDYPK   \n",
      "10006      373948  373949  B00474P712   AV34O625KH08P   \n",
      "10007      248835  248836  B0009JRH1C  A3PPSJXGW5MV8G   \n",
      "10008      263433  263434  B001E5E25Y  A250CQHA3GDXIE   \n",
      "10009      270205  270206  B002AQ0OS0  A1GNUW9KK32MTX   \n",
      "10010      301803  301804  B0016BU7GO  A1CR1DS15Z7XO1   \n",
      "10011      339819  339820  B0049RDI0Y  A161JAQJ1QKCTV   \n",
      "10012      469186  469187  B000AQFQC6  A1SU720MCEN7ME   \n",
      "10013       49009   49010  B0006G1K9I  A2WEQ41XW52FR8   \n",
      "10014      411605  411606  B000G1CPZQ   A40AJ0H77NZX5   \n",
      "10015      255684  255685  B000ORXYYS   A1VG6YYIRDO9W   \n",
      "10016      549595  549596  B002NWFW0G   A4OPNK2K0EDLG   \n",
      "10017      555694  555695  B001TLY7BM  A3P067FG6URLN7   \n",
      "10018      340649  340650  B000F498WC   AK9Z44QGP29YI   \n",
      "10019      287791  287792  B001HKFC28   AB3TFX36HZYZJ   \n",
      "10020      513373  513374  B004HOLD60  A3U5Z6UTIJ8FZ9   \n",
      "10021      419589  419590  B0029ZAOW8  A374M3QXNMK5R2   \n",
      "10022      356820  356821  B002YHU9LC  A2MYYF5OUBKTLZ   \n",
      "10023      419214  419215  B0002DGRQ6  A3JDAZ5YVHY15U   \n",
      "10024      361371  361372  B000KL57E8   AO7Q7BPAANAIO   \n",
      "10025      182496  182497  B008RWUKXK  A211NV3V47EOXY   \n",
      "10026      393562  393563  B003EMQGVI  A2IVO6H30VNC25   \n",
      "10027      191466  191467  B000WFN0VO   AHUYC6DE7Z0FG   \n",
      "10028       64557   64558  B000G82L62  A32AFX2PUJ82HG   \n",
      "10029      214718  214719  B001KQAR24  A1GOMLPSVMCJHY   \n",
      "...           ...     ...         ...             ...   \n",
      "10070      206061  206062  B000EDK5LM   AS637KBBA5ZMQ   \n",
      "10071      102793  102794  B0061PPLYI  A323X46F8GPACO   \n",
      "10072      227514  227515  B004BUU488  A3MANX4ZZXBP1C   \n",
      "10073      431444  431445  B000EVIDWW  A1S73WZTW3PP8M   \n",
      "10074      384378  384379  B002DHMVJ6  A1UKLUKXB6TWDP   \n",
      "10075      534963  534964  B005PXZ6JM  A3AEY7ED5KINO2   \n",
      "10076       86279   86280  B000084E6V  A1VL3GTRKWO3EC   \n",
      "10077      490379  490380  B000EDBPQ6   A8D4MAJXZQA6B   \n",
      "10078      296082  296083  B00013C2L6  A30LO4ZNPUTIX5   \n",
      "10079      221032  221033  B000ER6ZRG   AUK9D8R1FDX0F   \n",
      "10080       54615   54616  B001TLY7A8  A2LYSSWLGMM3A0   \n",
      "10081      437770  437771  B005A1LGIY   AR74YY08IP2WE   \n",
      "10082       71959   71960  B001E5DX4A  A166QEMAJ5LY1X   \n",
      "10083      438821  438822  B005HGAV8I  A2H7BLR1MTLA3F   \n",
      "10084      568242  568243  B003JHR4GE  A1KVV8I7DYPSVN   \n",
      "10085      277853  277854  B007KPWA8S  A1MBGLCPFLX3UP   \n",
      "10086       83749   83750  B0036VLZ8G  A2KIVODZRTGY4U   \n",
      "10087       62927   62928  B003OPCL5U  A2ABD9X340BR3I   \n",
      "10088      521326  521327  B001EPQNCO  A33U6HUGLKZIWY   \n",
      "10089      217312  217313  B00199CDTC  A3O9Z0EQ61OE46   \n",
      "10090      292515  292516  B0046HEPRM  A2528RR8NJDNJU   \n",
      "10091      252329  252330  B00060MRJQ  A3H6STVXAYJY0A   \n",
      "10092      213297  213298  B007RTR898   AS36DT5EPWNDY   \n",
      "10093      553728  553729  B001E5E3NK   AVVNWG8FEAHTR   \n",
      "10094      541343  541344  B002ZOCF0M  A1GF49GG7YYR0X   \n",
      "10095       58080   58081  B001VIY7O0  A1WM5VQTJ5X04G   \n",
      "10096       10660   10661  B004AE1FGK  A3T9AU6OZJO0WT   \n",
      "10097       84435   84436  B000ETAJZ8  A37GAGAZDFRMZ3   \n",
      "10098      308065  308066  B004M8JA98   AYBGJT704JPY4   \n",
      "10099       87193   87194  B001F6KGLG  A2O7AHS0SCWTG9   \n",
      "\n",
      "                                     ProfileName  HelpfulnessNumerator  \\\n",
      "10000                           shiprocks \"Bill\"                     0   \n",
      "10001                                    Ca girl                     3   \n",
      "10002                         Goldwave \"shopper\"                     3   \n",
      "10003                        Barbara B. Williams                     2   \n",
      "10004                                  grumpydan                     0   \n",
      "10005     Bernice Totty Brennan \"shopping maven\"                    11   \n",
      "10006    Mr. Stephen H. Ziker \"Kimball Kinnison\"                     0   \n",
      "10007                                    shele24                     9   \n",
      "10008                        chris \"teh castle.\"                     4   \n",
      "10009                                       Kate                     1   \n",
      "10010                                     Tiff D                     4   \n",
      "10011                             amazoner \"amo\"                     0   \n",
      "10012                           Mark R. Harrison                     1   \n",
      "10013                                        Rob                     1   \n",
      "10014                                  C. Gordon                     3   \n",
      "10015                                   alliedee                    74   \n",
      "10016                           Richard Spafford                     2   \n",
      "10017                         Wind Sock @ 2PONDS                     0   \n",
      "10018                         J. Paul \"joat-mon\"                     1   \n",
      "10019                                         D.                     4   \n",
      "10020                1.5 Trick Pony \"SuperDuper\"                     0   \n",
      "10021                         Pepper \"OmaPepper\"                     0   \n",
      "10022                                   R. Saini                     0   \n",
      "10023                            Shadow and Blue                     0   \n",
      "10024            Melinda L. Perry \"Yorkie Lover\"                     0   \n",
      "10025                            Andersen Prunty                     0   \n",
      "10026                    Paul Hearn \"Woodworker\"                    11   \n",
      "10027                                      Piper                     1   \n",
      "10028                      walstib11 \"walstib11\"                     3   \n",
      "10029                                Brenda Paul                     1   \n",
      "...                                          ...                   ...   \n",
      "10070                                        DSH                     1   \n",
      "10071                                 Pittie Mom                     2   \n",
      "10072                                   Squirley                     1   \n",
      "10073                               AmeliasMommy                     0   \n",
      "10074                  Eternity Grace \"Eternity\"                     0   \n",
      "10075                               Jayne Silver                     2   \n",
      "10076                                 LoveLily14                     0   \n",
      "10077                                     Phylis                     0   \n",
      "10078                                      Conan                     2   \n",
      "10079                                Huckleberry                     0   \n",
      "10080                                      zizzy                     1   \n",
      "10081                                Dave \"Dave\"                     1   \n",
      "10082                                   Diana K.                     0   \n",
      "10083                                M. Pfeiffer                     1   \n",
      "10084                                      Linda                     0   \n",
      "10085                                   AmberBug                     1   \n",
      "10086        Gwendolyn Dawson \"Literary License\"                     5   \n",
      "10087                                 karinkrupa                     0   \n",
      "10088                                  Sully7184                     0   \n",
      "10089                                       loki                     0   \n",
      "10090                                     TThorn                     1   \n",
      "10091                                    E. Chan                     0   \n",
      "10092                            Lovelylauren317                     0   \n",
      "10093                                     Lavine                     0   \n",
      "10094                            Michele Gentile                     0   \n",
      "10095                                 Amy Cannon                     0   \n",
      "10096  Alicia M. Webster \"perspicacious petunia\"                     2   \n",
      "10097             Rebecca K. Holmes \"scotflower\"                     0   \n",
      "10098                                     Marvin                     0   \n",
      "10099                                Kevin Kasha                     1   \n",
      "\n",
      "       HelpfulnessDenominator  Score        Time  \\\n",
      "10000                       0      4  1325203200   \n",
      "10001                       3      5  1234915200   \n",
      "10002                       3      4  1343779200   \n",
      "10003                       2      5  1273104000   \n",
      "10004                       0      5  1315872000   \n",
      "10005                      11      5  1230508800   \n",
      "10006                       0      2  1324080000   \n",
      "10007                       9      5  1297209600   \n",
      "10008                       4      5  1179100800   \n",
      "10009                       1      3  1294099200   \n",
      "10010                       4      5  1302048000   \n",
      "10011                       0      3  1331683200   \n",
      "10012                       1      2  1140652800   \n",
      "10013                       1      5  1320796800   \n",
      "10014                       5      5  1289433600   \n",
      "10015                      75      5  1326499200   \n",
      "10016                       2      5  1303257600   \n",
      "10017                       0      3  1340928000   \n",
      "10018                       2      3  1170720000   \n",
      "10019                       4      4  1248220800   \n",
      "10020                       0      5  1263513600   \n",
      "10021                       0      5  1313712000   \n",
      "10022                       0      5  1322697600   \n",
      "10023                       0      5  1296086400   \n",
      "10024                       0      4  1225324800   \n",
      "10025                       0      4  1319673600   \n",
      "10026                      72      1  1287360000   \n",
      "10027                       1      5  1291161600   \n",
      "10028                       3      4  1329091200   \n",
      "10029                       1      5  1260057600   \n",
      "...                       ...    ...         ...   \n",
      "10070                       1      5  1334620800   \n",
      "10071                       2      5  1278115200   \n",
      "10072                       1      4  1332806400   \n",
      "10073                       0      5  1291507200   \n",
      "10074                       0      5  1350086400   \n",
      "10075                       2      2  1330646400   \n",
      "10076                       0      5  1343347200   \n",
      "10077                       2      1  1348444800   \n",
      "10078                       3      5  1199577600   \n",
      "10079                       0      1  1327449600   \n",
      "10080                       1      5  1264982400   \n",
      "10081                       1      4  1320278400   \n",
      "10082                       0      5  1345420800   \n",
      "10083                       1      5  1340409600   \n",
      "10084                       0      5  1293753600   \n",
      "10085                       1      3  1344384000   \n",
      "10086                       5      5  1305590400   \n",
      "10087                       0      4  1320710400   \n",
      "10088                       0      5  1346371200   \n",
      "10089                       0      5  1349654400   \n",
      "10090                       1      5  1323734400   \n",
      "10091                       0      5  1148860800   \n",
      "10092                       0      4  1338508800   \n",
      "10093                       0      5  1335484800   \n",
      "10094                       0      5  1293235200   \n",
      "10095                       0      5  1332201600   \n",
      "10096                       2      3  1296345600   \n",
      "10097                       0      4  1252454400   \n",
      "10098                       0      4  1338336000   \n",
      "10099                       3      1  1297900800   \n",
      "\n",
      "                                                 Summary     ...      helpful  \\\n",
      "10000                                          neat soup     ...        False   \n",
      "10001                                     Comforting Tea     ...        False   \n",
      "10002                Better than other brands I've tried     ...        False   \n",
      "10003        had to doctor it up a bit but now I love it     ...        False   \n",
      "10004                                 Splenda Essentials     ...        False   \n",
      "10005                                              Great     ...         True   \n",
      "10006                        Marginally Chocolate Ginger     ...        False   \n",
      "10007                                     Love Love Love     ...         True   \n",
      "10008                             good tea, good bargain     ...         True   \n",
      "10009                   Pretty good for the (sale) price     ...        False   \n",
      "10010                                 GREAT for fat free     ...         True   \n",
      "10011                         How's it suppose to taste?     ...        False   \n",
      "10012                    Good product, terrible shipping     ...        False   \n",
      "10013                                    Nori Maki Arare     ...        False   \n",
      "10014          Vegetarian Chili is a Meatlover's Delight     ...        False   \n",
      "10015  A great product, but it is DEADLY to dogs and ...     ...         True   \n",
      "10016                                           Heavenly     ...        False   \n",
      "10017               Need magnifying glass to find liver.     ...        False   \n",
      "10018                                  Not As Advertised     ...        False   \n",
      "10019                                Smooth, but no bite     ...         True   \n",
      "10020                       Perfect snack, perfect size!     ...        False   \n",
      "10021            Great gentle energy boost! And healthy!     ...        False   \n",
      "10022                            Best home made popcorn!     ...        False   \n",
      "10023                          Great Product, Great deal     ...        False   \n",
      "10024                   My Yorkies LOVE Texas Toothpicks     ...        False   \n",
      "10025                       Eat Like a Woodland Creature     ...        False   \n",
      "10026                  Counting Calories? Think again...     ...        False   \n",
      "10027                  Smells fishy, so the cats love it     ...        False   \n",
      "10028                                           Good mix     ...        False   \n",
      "10029                         good deal and good quality     ...        False   \n",
      "...                                                  ...     ...          ...   \n",
      "10070  Perfect for making whole-grain bread.  No more...     ...        False   \n",
      "10071                                     Pit bull proof     ...        False   \n",
      "10072                                    Miracle noodles     ...        False   \n",
      "10073                                          So Yummy!     ...        False   \n",
      "10074        I hated PB&J as a kid. Still do. Love these     ...        False   \n",
      "10075  They worked really well until they started lea...     ...        False   \n",
      "10076                            My dog's favorite bone!     ...        False   \n",
      "10077                        These are amazing pancakes.     ...        False   \n",
      "10078                                          Wonderful     ...        False   \n",
      "10079               Turns into cement and choking hazard     ...        False   \n",
      "10080                         My buddies love this stuff     ...        False   \n",
      "10081  If you like Crystal Light and you like apple m...     ...        False   \n",
      "10082                                  Best cereal ever.     ...        False   \n",
      "10083                                  Just Fantastic!!!     ...        False   \n",
      "10084                                        Great value     ...        False   \n",
      "10085                            Only okay for a variety     ...        False   \n",
      "10086              A nice step up from plain rice cereal     ...         True   \n",
      "10087                                       Smooth taste     ...        False   \n",
      "10088          Great coffee, great price, great service!     ...        False   \n",
      "10089                                             Yummm!     ...        False   \n",
      "10090                                   Best Price Found     ...        False   \n",
      "10091                   It really does taste like apple!     ...        False   \n",
      "10092                                    So far so good!     ...        False   \n",
      "10093  Rid yourself of artificial sweetners without s...     ...        False   \n",
      "10094                         My Daily Regular Coffee...     ...        False   \n",
      "10095                   Best dog food bang for your buck     ...        False   \n",
      "10096                              A Little Disappointed     ...        False   \n",
      "10097                  Great to use in cheesecake crusts     ...        False   \n",
      "10098                             Tassimo French Vanilla     ...        False   \n",
      "10099                             Don't buy this product     ...        False   \n",
      "\n",
      "       hasSC hasbroken hasdidnt hasperfect haslove  hasEP hasdash reviewLen  \\\n",
      "10000  False     False    False      False   False  False   False       180   \n",
      "10001  False     False    False       True   False   True   False        97   \n",
      "10002  False     False    False      False   False  False    True       865   \n",
      "10003  False     False     True      False   False   True   False       355   \n",
      "10004  False     False    False      False   False   True   False       309   \n",
      "10005  False     False    False      False    True  False   False       383   \n",
      "10006  False     False    False      False   False  False   False       980   \n",
      "10007  False     False    False      False   False  False   False       254   \n",
      "10008  False     False    False      False   False  False    True       149   \n",
      "10009  False     False    False      False   False  False   False       301   \n",
      "10010  False     False    False      False   False  False   False       384   \n",
      "10011  False     False    False      False   False  False   False       356   \n",
      "10012  False     False    False      False   False  False   False       277   \n",
      "10013  False     False    False      False   False   True   False       140   \n",
      "10014  False     False    False      False    True   True   False      2601   \n",
      "10015   True     False    False      False    True   True    True      1623   \n",
      "10016  False     False    False      False   False   True   False       143   \n",
      "10017   True     False     True      False    True   True    True      1120   \n",
      "10018  False     False    False      False   False  False   False       133   \n",
      "10019  False     False    False      False    True  False   False       547   \n",
      "10020  False     False    False       True    True   True    True       958   \n",
      "10021  False     False    False      False    True   True   False       499   \n",
      "10022  False     False    False      False   False  False    True       162   \n",
      "10023  False     False    False      False    True   True   False       109   \n",
      "10024  False     False    False      False   False  False    True       193   \n",
      "10025  False     False    False      False   False  False   False      1601   \n",
      "10026  False     False    False      False   False  False    True       721   \n",
      "10027  False     False    False      False   False  False   False       342   \n",
      "10028  False     False    False      False   False  False   False       120   \n",
      "10029  False     False    False      False   False  False   False       326   \n",
      "...      ...       ...      ...        ...     ...    ...     ...       ...   \n",
      "10070  False     False    False      False   False  False    True       231   \n",
      "10071  False     False    False      False   False  False    True       633   \n",
      "10072  False     False    False      False   False  False   False       132   \n",
      "10073  False     False    False      False   False   True   False       306   \n",
      "10074  False     False    False      False   False  False    True       549   \n",
      "10075  False     False     True      False    True  False   False       583   \n",
      "10076  False     False    False       True   False   True   False       736   \n",
      "10077  False     False    False      False   False  False   False       353   \n",
      "10078  False     False    False      False   False  False   False       156   \n",
      "10079  False     False    False      False   False  False   False       369   \n",
      "10080  False     False    False      False   False   True    True        93   \n",
      "10081  False     False    False      False   False  False   False       297   \n",
      "10082  False     False    False      False   False  False    True       163   \n",
      "10083  False      True    False      False   False  False    True       717   \n",
      "10084  False     False    False      False   False  False   False       149   \n",
      "10085  False     False    False      False   False   True   False       506   \n",
      "10086  False     False    False      False   False  False    True       572   \n",
      "10087  False     False    False      False   False   True   False       133   \n",
      "10088  False     False    False      False   False   True   False       134   \n",
      "10089  False     False    False      False   False  False   False       424   \n",
      "10090  False     False    False      False   False  False   False       186   \n",
      "10091  False     False    False      False   False   True   False       273   \n",
      "10092  False     False    False      False   False   True    True       912   \n",
      "10093  False     False    False      False    True   True   False       643   \n",
      "10094  False     False    False      False   False  False    True       707   \n",
      "10095  False     False    False      False   False  False   False       285   \n",
      "10096  False      True    False      False   False  False   False       488   \n",
      "10097   True     False    False      False   False  False    True       507   \n",
      "10098  False     False    False      False   False  False   False       133   \n",
      "10099  False     False    False      False   False   True   False       505   \n",
      "\n",
      "      duplicateIds  \n",
      "10000        False  \n",
      "10001        False  \n",
      "10002         True  \n",
      "10003        False  \n",
      "10004        False  \n",
      "10005         True  \n",
      "10006        False  \n",
      "10007        False  \n",
      "10008         True  \n",
      "10009        False  \n",
      "10010        False  \n",
      "10011        False  \n",
      "10012        False  \n",
      "10013        False  \n",
      "10014        False  \n",
      "10015        False  \n",
      "10016        False  \n",
      "10017        False  \n",
      "10018        False  \n",
      "10019        False  \n",
      "10020        False  \n",
      "10021        False  \n",
      "10022         True  \n",
      "10023        False  \n",
      "10024        False  \n",
      "10025        False  \n",
      "10026        False  \n",
      "10027         True  \n",
      "10028        False  \n",
      "10029        False  \n",
      "...            ...  \n",
      "10070        False  \n",
      "10071        False  \n",
      "10072        False  \n",
      "10073        False  \n",
      "10074        False  \n",
      "10075        False  \n",
      "10076        False  \n",
      "10077        False  \n",
      "10078        False  \n",
      "10079        False  \n",
      "10080        False  \n",
      "10081        False  \n",
      "10082        False  \n",
      "10083        False  \n",
      "10084        False  \n",
      "10085        False  \n",
      "10086        False  \n",
      "10087        False  \n",
      "10088        False  \n",
      "10089        False  \n",
      "10090        False  \n",
      "10091        False  \n",
      "10092        False  \n",
      "10093        False  \n",
      "10094        False  \n",
      "10095        False  \n",
      "10096        False  \n",
      "10097        False  \n",
      "10098        False  \n",
      "10099        False  \n",
      "\n",
      "[100 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data[10000:10100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   2, 206,   0],\n",
       "       [  0,   0,   0, ...,   5, 125,   0],\n",
       "       [  1,   0,   0, ...,   5, 678,   0],\n",
       "       ..., \n",
       "       [  0,   0,   0, ...,   5, 283,   0],\n",
       "       [  0,   0,   0, ...,   5, 266,   0],\n",
       "       [  0,   0,   0, ...,   5, 275,   1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = data.iloc[:, 13].values.reshape(data.shape[0], 1)\n",
    "x2 = data.iloc[:, 14].values.reshape(data.shape[0], 1)\n",
    "x3 = data.iloc[:, 15].values.reshape(data.shape[0], 1)\n",
    "x4 = data.iloc[:, 16].values.reshape(data.shape[0], 1)\n",
    "x5 = data.iloc[:, 17].values.reshape(data.shape[0], 1)\n",
    "x6 = data.iloc[:, 18].values.reshape(data.shape[0], 1)\n",
    "x7 = data.iloc[:, 19].values.reshape(data.shape[0], 1)\n",
    "\n",
    "XScore = data.iloc[:, 7].values.reshape(data.shape[0], 1)\n",
    "XreviewLen = data.iloc[:, 20].values.reshape(data.shape[0], 1)\n",
    "XIddups = data.iloc[:, 21].values.reshape(data.shape[0], 1)\n",
    "\n",
    "Xtoadd = np.concatenate((x1, x2, x3, x4, x5, x6, x7, XScore, XreviewLen, XIddups), axis=1)\n",
    "Xtoadd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_results():\n",
    "    print('Error rate on training set: ')\n",
    "    print((y_train != y_pred).sum() / X_train.shape[0])\n",
    "    print('Accuracy rate on training set: ')\n",
    "    print(1 - (y_train != y_pred).sum() / X_train.shape[0])\n",
    "    print('True positive rate on training tet:')\n",
    "    print(((y_train==True) & (y_pred==True)).sum() / y_train.sum())\n",
    "    print('**************')\n",
    "    print('Error rate on test set: ')\n",
    "    print((y_test != y_pred_test).sum() / X_test.shape[0])\n",
    "    print('Accuracy rate on test set: ')\n",
    "    print(1 - (y_test != y_pred_test).sum() / X_test.shape[0])\n",
    "    print('True positive rate on test set')\n",
    "    print(((y_test==True) & (y_pred_test==True)).sum() / y_test.sum())\n",
    "    print('True negative rate on test set')\n",
    "    print(((y_test==False) & (y_pred_test==False)).sum() / (y_test.shape[0] - y_test.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "hv = HashingVectorizer(n_features=2 ** 17, non_negative=True) ##use n_features= to restrict features\n",
    "X = hv.transform(data.Text)\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "XtoaddSparse = csr_matrix(Xtoadd)\n",
    "Xfinal = hstack([X, XtoaddSparse])\n",
    "X = csr_matrix(Xfinal)\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455000, 131082)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455000,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.iloc[:, 12].values\n",
    "y.shape\n",
    "#type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on training set: \n",
      "0.0737519623234\n",
      "Accuracy rate on training set: \n",
      "0.926248037677\n",
      "True positive rate on training tet:\n",
      "0.463664542793\n",
      "**************\n",
      "Error rate on test set: \n",
      "0.115435897436\n",
      "Accuracy rate on test set: \n",
      "0.884564102564\n",
      "True positive rate on test set\n",
      "0.244229039672\n",
      "True negative rate on test set\n",
      "0.935221711873\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on training set: \n",
      "0.0659686028257\n",
      "Accuracy rate on training set: \n",
      "0.934031397174\n",
      "True positive rate on training tet:\n",
      "0.512011365593\n",
      "**************\n",
      "Error rate on test set: \n",
      "0.114146520147\n",
      "Accuracy rate on test set: \n",
      "0.885853479853\n",
      "True positive rate on test set\n",
      "0.264115119416\n",
      "True negative rate on test set\n",
      "0.93503988363\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on training set: \n",
      "0.13464678179\n",
      "Accuracy rate on training set: \n",
      "0.86535321821\n",
      "True positive rate on training tet:\n",
      "0.645126571379\n",
      "**************\n",
      "Error rate on test set: \n",
      "0.178271062271\n",
      "Accuracy rate on test set: \n",
      "0.821728937729\n",
      "True positive rate on test set\n",
      "0.370240831418\n",
      "True negative rate on test set\n",
      "0.857446657127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on training set: \n",
      "0.0753971742543\n",
      "Accuracy rate on training set: \n",
      "0.924602825746\n",
      "True positive rate on training tet:\n",
      "0.47124160496\n",
      "**************\n",
      "Error rate on test set: \n",
      "0.118249084249\n",
      "Accuracy rate on test set: \n",
      "0.881750915751\n",
      "True positive rate on test set\n",
      "0.244728689917\n",
      "True negative rate on test set\n",
      "0.932146442886\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "y_pred = lr.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = lr.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
