{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 1000000)\n",
    "pd.set_option('display.max_rows', 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455000, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>helpScore</th>\n",
       "      <th>helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138806</td>\n",
       "      <td>138807</td>\n",
       "      <td>B000E63LME</td>\n",
       "      <td>A1CQGW1AOD0LF2</td>\n",
       "      <td>Alena K. \"Alena\"</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1294185600</td>\n",
       "      <td>Not as pictured.</td>\n",
       "      <td>I was looking forward to try cranberry apple f...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>469680</td>\n",
       "      <td>469681</td>\n",
       "      <td>B004ZIH4KM</td>\n",
       "      <td>A37S7U1OX2MCWI</td>\n",
       "      <td>Becky Cole</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1349740800</td>\n",
       "      <td>seeds</td>\n",
       "      <td>TY for everything.  The seeds arrived quickly,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238202</td>\n",
       "      <td>238203</td>\n",
       "      <td>B003ZXE9QA</td>\n",
       "      <td>A2OM6G73E64EQ9</td>\n",
       "      <td>jeff</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1329264000</td>\n",
       "      <td>I'm addicted!</td>\n",
       "      <td>I've finally found the best cereal in the worl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>485307</td>\n",
       "      <td>485308</td>\n",
       "      <td>B001RVFERK</td>\n",
       "      <td>A25W349EE97NBK</td>\n",
       "      <td>Tangent4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1248307200</td>\n",
       "      <td>I wanted to love these...</td>\n",
       "      <td>I originally bought these chips because I'd he...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>375283</td>\n",
       "      <td>375284</td>\n",
       "      <td>B000OQZNTS</td>\n",
       "      <td>A3CPPW0HUC07YS</td>\n",
       "      <td>Amy Nicolai</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1333238400</td>\n",
       "      <td>Excellent chamomile tea</td>\n",
       "      <td>Really excellent tea, flowers are visible in t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Id   ProductId          UserId       ProfileName  \\\n",
       "0      138806  138807  B000E63LME  A1CQGW1AOD0LF2  Alena K. \"Alena\"   \n",
       "1      469680  469681  B004ZIH4KM  A37S7U1OX2MCWI        Becky Cole   \n",
       "2      238202  238203  B003ZXE9QA  A2OM6G73E64EQ9              jeff   \n",
       "3      485307  485308  B001RVFERK  A25W349EE97NBK          Tangent4   \n",
       "4      375283  375284  B000OQZNTS  A3CPPW0HUC07YS       Amy Nicolai   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       2      2  1294185600   \n",
       "1                     0                       0      5  1349740800   \n",
       "2                     0                       0      5  1329264000   \n",
       "3                     1                       1      4  1248307200   \n",
       "4                     0                       0      5  1333238400   \n",
       "\n",
       "                     Summary  \\\n",
       "0           Not as pictured.   \n",
       "1                      seeds   \n",
       "2              I'm addicted!   \n",
       "3  I wanted to love these...   \n",
       "4    Excellent chamomile tea   \n",
       "\n",
       "                                                Text  helpScore helpful  \n",
       "0  I was looking forward to try cranberry apple f...        0.5   False  \n",
       "1  TY for everything.  The seeds arrived quickly,...        NaN   False  \n",
       "2  I've finally found the best cereal in the worl...        NaN   False  \n",
       "3  I originally bought these chips because I'd he...        1.0   False  \n",
       "4  Really excellent tea, flowers are visible in t...        NaN   False  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Amazon.csv')\n",
    "print(data.shape)\n",
    "data.Summary = data.Summary.fillna('0')\n",
    "data.ProfileName = data.ProfileName.fillna(' ')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianssmith/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "data['hasSC'] = data['Text'].str.contains(';')\n",
    "data['hasbroken'] = data['Text'].str.contains('broken')\n",
    "data['hasdidnt'] = data['Text'].str.contains('didn\\'t')\n",
    "data['hasperfect'] = data['Text'].str.contains('perfect')\n",
    "data['haslove'] = data['Text'].str.contains('love')\n",
    "data['hasEP'] = data['Text'].str.contains('!')\n",
    "data['hasdash'] = data['Text'].str.contains('-')\n",
    "data['hasChocolate'] = data['Text'].str.contains('chocolate')\n",
    "data['hasCoffee'] = data['Text'].str.contains('coffee')\n",
    "data['hasRec'] = data['Text'].str.contains('recommend')\n",
    "data['hasTerrible'] = data['Text'].str.contains('terrible')\n",
    "\n",
    "\n",
    "\n",
    "data['sumEP'] = data['Summary'].str.contains('!')\n",
    "data['sumPeriod'] = data['Summary'].str.contains('.')\n",
    "data['nameSpace'] = data['ProfileName'].str.contains(' ')\n",
    "\n",
    "data['sumLen'] = data['Summary'].str.len()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data['reviewLen'] = data['Text'].str.len()\n",
    "data['duplicateIds'] = data.UserId.duplicated()\n",
    "data['nameLen'] = data['ProfileName'].str.len()\n",
    "\n",
    "data['sumtexdif'] = data['Text'].str.len() - data['Summary'].str.len()\n",
    "data.sumtexdif[data.sumtexdif < 0] = 0\n",
    "\n",
    "data['sumComma'] = data['Summary'].str.contains(',')\n",
    "data['sumColon'] = data['Summary'].str.contains(':')\n",
    "data['sumSC'] = data['Summary'].str.contains(';')\n",
    "data['sumDash'] = data['Summary'].str.contains('-')\n",
    "\n",
    "data['hasComma'] = data['Text'].str.contains(',')\n",
    "data['hasColon'] = data['Text'].str.contains(':')\n",
    "\n",
    "data['ProductCounts'] = data.groupby('ProductId')['ProductId'].transform('count')\n",
    "data['UserCounts'] = data.groupby('UserId')['UserId'].transform('count')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XScore = data.iloc[:, 7].values.reshape(data.shape[0], 1)\n",
    "\n",
    "hasSC = data.iloc[:, 13].values.reshape(data.shape[0], 1)\n",
    "hasbroken = data.iloc[:, 14].values.reshape(data.shape[0], 1)\n",
    "hasdidnt = data.iloc[:, 15].values.reshape(data.shape[0], 1)\n",
    "hasperfect = data.iloc[:, 16].values.reshape(data.shape[0], 1)\n",
    "haslove = data.iloc[:, 17].values.reshape(data.shape[0], 1)\n",
    "hasEP = data.iloc[:, 18].values.reshape(data.shape[0], 1)\n",
    "hasdash = data.iloc[:, 19].values.reshape(data.shape[0], 1)\n",
    "hasChocolate = data.iloc[:, 20].values.reshape(data.shape[0],1)\n",
    "\n",
    "hasCoffee = data.iloc[:, 21].values.reshape(data.shape[0],1)\n",
    "\n",
    "hasRec = data.iloc[:, 22].values.reshape(data.shape[0],1)\n",
    "hasTerrible = data.iloc[:, 23].values.reshape(data.shape[0],1)\n",
    "\n",
    "sumEP = data.iloc[:, 24].values.reshape(data.shape[0],1)\n",
    "sumPeriod = data.iloc[:, 25].values.reshape(data.shape[0],1)\n",
    "nameSpace = data.iloc[:, 26].values.reshape(data.shape[0],1)\n",
    "\n",
    "sumLen = data.iloc[:, 27].values.reshape(data.shape[0],1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "XreviewLen = data.iloc[:, 28].values.reshape(data.shape[0], 1)\n",
    "XIddups = data.iloc[:, 29].values.reshape(data.shape[0], 1)\n",
    "\n",
    "nameLen = data.iloc[:, 30].values.reshape(data.shape[0], 1)\n",
    "\n",
    "sumtexdif = data.iloc[:, 31].values.reshape(data.shape[0], 1)\n",
    "\n",
    "sumComma = data.iloc[:, 32].values.reshape(data.shape[0],1)\n",
    "sumColon = data.iloc[:, 33].values.reshape(data.shape[0],1)\n",
    "sumSC = data.iloc[:, 34].values.reshape(data.shape[0],1)\n",
    "sumDash = data.iloc[:, 35].values.reshape(data.shape[0],1)\n",
    "hasComma = data.iloc[:, 36].values.reshape(data.shape[0],1)\n",
    "hasColon = data.iloc[:, 37].values.reshape(data.shape[0],1)\n",
    "ProductCounts = data.iloc[:, 38].values.reshape(data.shape[0],1)\n",
    "UserCounts = data.iloc[:, 39].values.reshape(data.shape[0],1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Xtoadd = np.concatenate(( hasSC, hasbroken, hasdidnt, hasperfect, \n",
    "                         haslove, hasEP, hasdash, XScore, XreviewLen,\n",
    "                         XIddups, hasChocolate, hasCoffee, hasRec,\n",
    "                         hasTerrible, sumtexdif, sumEP, sumPeriod,\n",
    "                         sumLen, nameLen, nameSpace, sumComma, sumColon,\n",
    "                         sumSC, sumDash, hasComma, hasColon, ProductCounts, UserCounts), axis=1)\n",
    "#type(Xtoadd)\n",
    "#data.iloc[100000:101000, 27]\n",
    "Xtoadd.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_results():\n",
    "    print('Error rate on training set: ')\n",
    "    print((y_train != y_pred).sum() / X_train.shape[0])\n",
    "    print('Accuracy rate on training set: ')\n",
    "    print(1 - (y_train != y_pred).sum() / X_train.shape[0])\n",
    "    print('True positive rate on training tet:')\n",
    "    print(((y_train==True) & (y_pred==True)).sum() / y_train.sum())\n",
    "    print('**************')\n",
    "    print('Error rate on test set: ')\n",
    "    print((y_test != y_pred_test).sum() / X_test.shape[0])\n",
    "    print('Accuracy rate on test set: ')\n",
    "    print(1 - (y_test != y_pred_test).sum() / X_test.shape[0])\n",
    "    print('True positive rate on test set')\n",
    "    print(((y_test==True) & (y_pred_test==True)).sum() / y_test.sum())\n",
    "    print('True negative rate on test set')\n",
    "    print(((y_test==False) & (y_pred_test==False)).sum() / (y_test.shape[0] - y_test.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "hv = HashingVectorizer(n_features=2 ** 17, non_negative=True) ##use n_features= to restrict features\n",
    "X = hv.transform(data.Text)\n",
    "Xsum = hv.transform(data.Summary)\n",
    "Xname = hv.transform(data.ProfileName)\n",
    "Xuid = hv.transform(data.UserId)\n",
    "Xpid = hv.transform(data.ProductId)\n",
    " \n",
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.stem\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "english_stemmer = nltk.stem.SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (english_stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = StemmedCountVectorizer(min_df=1,\n",
    "stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xstemmer = vectorizer.fit_transform(data.Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "XtoaddSparse = csr_matrix(Xtoadd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xfinal = hstack([X, Xsum, Xname, Xpid, Xuid, Xstemmer, XtoaddSparse])\n",
    "X = csr_matrix(Xfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = data.iloc[:, 12].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on training set: \n",
      "0.0729293563579\n",
      "Accuracy rate on training set: \n",
      "0.927070643642\n",
      "True positive rate on training tet:\n",
      "0.0\n",
      "**************\n",
      "Error rate on test set: \n",
      "0.0733113553114\n",
      "Accuracy rate on test set: \n",
      "0.926688644689\n",
      "True positive rate on test set\n",
      "0.0\n",
      "True negative rate on test set\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on training set: \n",
      "0.000210361067504\n",
      "Accuracy rate on training set: \n",
      "0.999789638932\n",
      "True positive rate on training tet:\n",
      "0.998622352333\n",
      "**************\n",
      "Error rate on test set: \n",
      "0.0930769230769\n",
      "Accuracy rate on test set: \n",
      "0.906923076923\n",
      "True positive rate on test set\n",
      "0.385230338763\n",
      "True negative rate on test set\n",
      "0.948194761765\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on training set: \n",
      "0.344260596546\n",
      "Accuracy rate on training set: \n",
      "0.655739403454\n",
      "True positive rate on training tet:\n",
      "0.587911141726\n",
      "**************\n",
      "Error rate on test set: \n",
      "0.355985347985\n",
      "Accuracy rate on test set: \n",
      "0.644014652015\n",
      "True positive rate on test set\n",
      "0.574497851504\n",
      "True negative rate on test set\n",
      "0.649514202367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on training set: \n",
      "0.00469387755102\n",
      "Accuracy rate on training set: \n",
      "0.995306122449\n",
      "True positive rate on training tet:\n",
      "0.965860168762\n",
      "**************\n",
      "Error rate on test set: \n",
      "0.0948424908425\n",
      "Accuracy rate on test set: \n",
      "0.905157509158\n",
      "True positive rate on test set\n",
      "0.382132507245\n",
      "True negative rate on test set\n",
      "0.946534590847\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on training set: \n",
      "0.0677205651491\n",
      "Accuracy rate on training set: \n",
      "0.932279434851\n",
      "True positive rate on training tet:\n",
      "0.0951007404856\n",
      "**************\n",
      "Error rate on test set: \n",
      "0.0718315018315\n",
      "Accuracy rate on test set: \n",
      "0.928168498168\n",
      "True positive rate on test set\n",
      "0.0668532027581\n",
      "True negative rate on test set\n",
      "0.9963080961\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "y_pred = lr.fit(X_train, y_train).predict(X_train)\n",
    "y_pred_test = lr.predict(X_test)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
